{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6f20659",
   "metadata": {},
   "source": [
    "# Machine Learning Assignment 6 solution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df66d364",
   "metadata": {},
   "source": [
    "### 1. In the sense of machine learning, what is a model? What is the best way to train a model?\n",
    "\n",
    "### Ans:\n",
    "\n",
    "A machine learning model is a file that has been trained to recognize certain types of patterns. You train a model over a set of data, providing it an algorithm that it can use to make decision and learn from those data.\n",
    "\n",
    "The best way to train a model is with cross validation. Which is a resampling method that uses different propertion of the data to tarin and test the model on different iterations.\n",
    "\n",
    "We use cross-validation because after training a model, it is not guaranteed that the model will perform well on unseen data. The model should be validated. Cross-validation is a standard procedure in data analysis, and it’s commonly used to determine the reliability of machine learning algorithms. It’s a vital step when building models for real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64968c4c",
   "metadata": {},
   "source": [
    "### 2. In the sense of machine learning, explain the \"No Free Lunch\" theorem.\n",
    "\n",
    "### Ans:\n",
    "\n",
    "The **No Free Lunch Theorem**  is often thrown around in the field of optimization and machine learning, often with little understanding of what it means or implies.\n",
    "\n",
    "The theorem states that all optimization algorithms perform equally well when their performance is averaged across all possible problems.\n",
    "\n",
    "It implies that there is no single best optimization algorithm. Because of the close relationship between optimization, search, and machine learning, it also implies that there is no single best machine learning algorithm for predictive modeling problems such as classification and regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a7facf",
   "metadata": {},
   "source": [
    "### 3. Describe the K-fold cross-validation mechanism in detail.\n",
    "\n",
    "\n",
    "### Ans:\n",
    "\n",
    "\n",
    "**Cross-validation** is a resampling technique used to validate machine learning models against a limited sample of data. It’s a way to verify the performance of a predictive model before using it in an actual situation. Essentially, it helps you avoid creating inaccurate predictions. Using multiple training sets is crucial when performing cross-validation. You must have multiple test sets to ensure your model performs as expected.\n",
    "\n",
    "\n",
    "\n",
    "Cross-validation is a resampling technique used to estimate the power of machine learning models. Cross-validation is primarily required to estimate your predictive model’s performance accuracy.\n",
    "\n",
    "\n",
    "\n",
    "After training a model, it is not guaranteed that the model will perform well on unseen data. The model should be validated. This validation process is called cross-validation. Cross-validation is a standard procedure in data analysis, and it’s commonly used to determine the reliability of machine learning algorithms. It’s a vital step when building models for real-world applications.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**K-fold cross validation** In K-fold cross-validation, the data set is divided into a number of K-folds and used to assess the model’s ability as new data become available. K represents the number of groups into which the data sample is divided. For example, if you find the k value to be 5, you can call it 5-fold cross-validation. Each fold is used as a train set and test set at some point in the process.\n",
    "\n",
    "**.** Randomly shuffle the dataset.\n",
    "\n",
    "**.** Divide the dataset into k folds\n",
    "\n",
    "**.** For each unique group:\n",
    "\n",
    "1.Use one fold as test data\n",
    "\n",
    "\n",
    "2.Use remaining groups as training dataset\n",
    "\n",
    "\n",
    "\n",
    "3.Fit model on training set and evaluate on test set\n",
    "\n",
    "\n",
    "4.Keep Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212632e0",
   "metadata": {},
   "source": [
    "### 4. Describe the bootstrap sampling method. What is the aim of it?\n",
    "\n",
    "### Ans:\n",
    "\n",
    "In statistics, **Bootstrap Sampling** is a method that involves drawing of sample data repeatedly with replacement from a data source to estimate a population parameter. Importantly, samples are constructed by drawing observations from a large data sample one at a time and returning them to the data sample after they have been chosen. This allows a given observation to be included in a given small sample more than once. This approach to sampling is called sampling with replacement.\n",
    "\n",
    "\n",
    "**Sampling:** With respect to statistics, sampling is the process of selecting a subset of items from a vast collection of items (population) to estimate a certain characteristic of the entire population\n",
    "\n",
    "\n",
    "**Sampling with replacement:** It means a data point in a drawn sample can reappear in future drawn samples as well\n",
    "\n",
    "\n",
    "\n",
    "**Parameter estimation:** It is a method of estimating parameters for the population using samples. A parameter is a measurable characteristic associated with a population. For example, the average height of residents in a city, the count of red blood cells, etc.\n",
    "\n",
    "\n",
    "\n",
    "The process for building one sample can be summarized as follows:\n",
    "\n",
    "1. Choose the size of the sample.\n",
    "\n",
    "\n",
    "2. While the size of the sample is less than the chosen size\n",
    "\n",
    "i. Randomly select an observation from the dataset\n",
    "\n",
    "ii. Add it to the sample\n",
    "\n",
    "The bootstrap method can be used to estimate a quantity of a population. This is done by repeatedly taking small samples, calculating the statistic, and taking the average of the calculated statistics. We can summarize this procedure as follows:\n",
    "\n",
    "1. Choose a number of bootstrap samples to perform\n",
    "\n",
    "\n",
    "2. Choose a sample size\n",
    "\n",
    "\n",
    "3. For each bootstrap sample\n",
    "\n",
    "i. Draw a sample with replacement with the chosen size\n",
    "\n",
    "ii. Calculate the statistic on the sample\n",
    "\n",
    "iii. Calculate the mean of the calculated sample statistics.\n",
    "\n",
    "The procedure aims to estimate the skill of a machine learning model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d125602",
   "metadata": {},
   "source": [
    "### 5. What is the significance of calculating the Kappa value for a classification model? Demonstrate how to measure the Kappa value of a classification model using a sample collection of results.\n",
    "\n",
    "\n",
    "**Ans:** Kappa value or Cohen's **Kappa** coefficient is an evaluation metric for classification models. Its significance as an evaluation metric is that it can be used to evaluate multi class classification models and also works on models trained on imbalanced datasets(scores like accuracy scores fail for imbalanced datasets).\n",
    "\n",
    "In simpler words It basically tells you how much better your classifier is performing over the performance of a classifier that simply guesses at random according to the frequency of each class. Cohen's kappa is always less than or equal to 1. Values of 0 or less, indicate that the classifier is useless Cohen suggested the Kappa result be interpreted as follows: values ≤ 0 as indicating no agreement and 0.01–0.20 as none to slight, 0.21–0.40 as fair, 0.41– 0.60 as moderate, 0.61–0.80 as substantial, and 0.81–1.00 as almost perfect agreement."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307f36ea",
   "metadata": {},
   "source": [
    "The kappa score is an interesting metric. Its origins are in the field of psychology: it is used for measuring the agreement between two human evaluators or raters (e.g., psychologists) when rating subjects (patients). It was later “appropriated” by the machine-learning community to measure classification performance.\n",
    "\n",
    "The formula for Cohen's kappa is the probability of agreement minus the probability of random agreement, divided by one minus the probability of random agreement. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8542838f",
   "metadata": {},
   "source": [
    "k = po -pe / 1 - pe  = 1 - po / 1 - pe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a16c0f",
   "metadata": {},
   "source": [
    "### 6. Describe the model ensemble method. In machine learning, what part does it play?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Ans:\n",
    "\n",
    "\n",
    "\n",
    "The technique where we use **multiple decision makers** to make a decision is called **ensemble techniques**, so that we will \n",
    "\n",
    "get **strong outcome**.\n",
    "\n",
    "\n",
    "In ensemble techniques we will resolve classification and regression problems. This algorithm arranged in such a way that the \n",
    "\n",
    "base algorithm with multiple other algorithms contribute together to make a decision. (eg: If we are using multiple decision \n",
    "\n",
    "trees to make a decision which reduces the biasness)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2c06acd",
   "metadata": {},
   "source": [
    "### 7. What is a descriptive model's main purpose? Give examples of real-world problems that descriptive models were used to solve.\n",
    "\n",
    "### Ans:\n",
    "\n",
    "**Descriptive modeling** is a mathematical process that describes real-world events and the relationships between factors \n",
    "\n",
    "responsible for them. The process is used by consumer-driven organizations to help them target their marketing and advertising \n",
    "\n",
    "efforts."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77454bd3",
   "metadata": {},
   "source": [
    "### 8. Describe how to evaluate a linear regression model.\n",
    "\n",
    "### Ans:\n",
    "\n",
    "To evaluate a linear regression model we use R Square/Adjusted R Square.\n",
    "\n",
    "\n",
    "**R Squared**: R-squared score defines the performance of your model, not the absolute loss. MAE and MSE depend on the context, \n",
    "\n",
    "where as R-squared score is independent of context. So in R-square value we have a baseline model to compare. The same we have \n",
    "\n",
    "\n",
    "in classification problems where threshold is fixed at 0.5. Basically R-squared value calculates how much regression line is \n",
    "\n",
    "better than the mean line. R-squared value ranges between 0 to 1. Which means the accuracy of your model. If R-squared value is \n",
    "\n",
    "negative then our model is considered as very bad model. If R-squared value is 1, then all the points fit in the line and we \n",
    "\n",
    "get the best fit line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250adf4a",
   "metadata": {},
   "source": [
    "<img src = \"https://www.gstatic.com/education/formulas2/472522532/en/coefficient_of_determination.svg\" width=\"200\" heigth=\"100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6bcf4d0",
   "metadata": {},
   "source": [
    "WHERE,\n",
    "\n",
    "##### R^2=coefficient of determination\n",
    "\n",
    "##### RSS=sum of squares of residuals\n",
    "\n",
    "##### TS=total sum of squares\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34d9508",
   "metadata": {},
   "source": [
    "TSS is a constant depends on data. It is the distance between original data and average line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843acd9c",
   "metadata": {},
   "source": [
    "#### Drawbacks :\n",
    "\n",
    "When there are multiple features in the model and features are highly correlated, the increase in accuracy will be very high in \n",
    "\n",
    "R squared, later if there will be irrelevant feature while calculating the accuracy there will be a small increase but there is \n",
    "\n",
    "no direct correlation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a4936b1",
   "metadata": {},
   "source": [
    "**Adjusted R-squared:** Adjusted R-square came into picture to overcome the drawbacks of R-squared. It determines the accuracy \n",
    "\n",
    "of our model based on importance of features (No biasness). In adjusted R-square if there is any feature which is not highly \n",
    "\n",
    "correlated then it’ll decrease the accuracy of our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86b5ac01",
   "metadata": {},
   "source": [
    "<img src = \"https://i.stack.imgur.com/RcGf6.png\" width=\"500\" heigth=\"300\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2e8691",
   "metadata": {},
   "source": [
    "As per R-squared value all the independent variables affect the result of the model,\n",
    "\n",
    "whereas the adjusted-R squared value defines only the independent variables which actually have an effect on the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42244a9c",
   "metadata": {},
   "source": [
    "### 9. Distinguish :\n",
    "\n",
    "1. Descriptive vs. predictive models\n",
    "\n",
    "2. Underfitting vs. overfitting the model\n",
    "3. Bootstrapping vs. cross-validation\n",
    "\n",
    "\n",
    "**Ans:** The differences between:\n",
    "\n",
    "##### Descriptive vs. predictive models\n",
    "\n",
    "1. Descriptive models are built to identify trends and underlying patterns.\n",
    "\n",
    "2. Predictive models are built to predict a dependent variable value.\n",
    "\n",
    "3. Most of descriptive models are built using unsupervised machine learning.\n",
    "\n",
    "4. Most of predictive models are built using classification and regression models.\n",
    "\n",
    "5. Example for descriptive model: Finding why consumers are engaging more with a social media post.\n",
    "\n",
    "6. Example for predictive model: Predicting the chances of cancer in a patient.\n",
    "\n",
    "##### Underfitting vs. overfitting the model\n",
    "\n",
    "1. Underfitting is a situation arising when the hypothesis is way too simple, or when the machine learning model is way too simple to produce good results.\n",
    "\n",
    "2. Overfitting is a situation arising when the hypothesis is way too complex, or when the machine learning model is way too complex to produce good results.\n",
    "\n",
    "3. Underfitting causes a model to produce poor results due to heavily simplified algorithm reacting lightly to changes in the unseen data for independent variables from the training data.\n",
    "\n",
    "4. Overfitting makes a model produce poor results due to slightest variations in the unseen data for independent variables from the training data\n",
    "\n",
    "5. Underfitting is also called High Bias.\n",
    "\n",
    "6. Overfitting is also called High variance\n",
    "\n",
    "##### Bootstrapping vs cross-validation\n",
    "\n",
    "1. Boostrap sampling is a method of sampling in which the repeated sampling is done with replacement using a data D in random draws over which machine learning models are trained for better performance.\n",
    "\n",
    "2. Cross validation is a method used to check the efficacy of the machine learning model on test data.\n",
    "\n",
    "3. End goal of bootstrapping is to reduce overfitting and increase performance.\n",
    "\n",
    "4. End goal of cross validation is only to produce test scores to check efficacy of model\n",
    "\n",
    "\n",
    "5. Bootstrapping is best employed in Random Forest Classifier.\n",
    "\n",
    "6. Cross Validation is best employed using K-fold cross validation technique.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 10. Make quick notes on:\n",
    "\n",
    "1. LOOCV.\n",
    "\n",
    "2. F-measurement\n",
    "\n",
    "3. The width of the silhouette\n",
    "\n",
    "4. Receiver operating characteristic curve\n",
    "\n",
    "**Ans:** The Quick notes on: **LOOCV** or Leave One Out Cross Validation is a form of K-fold cross validation where only one \n",
    "\n",
    "observation is left out for validation purpose while the rest of the data is used for model training each iteration. It is \n",
    "\n",
    "computationally taxing and should only be used for data with low dimensionality.\n",
    "\n",
    "\n",
    "Harmonic mean of Precision score and recall score is called **F-measurement or F-score**. It is formulated as 2 (pr re)/pr +re \n",
    "\n",
    "where pr is precision score and re is recall score.\n",
    "\n",
    "\n",
    "\n",
    "Estimate of average inter cluster distance to give efficacy/performance of cluster algorithms is called **width of the \n",
    "\n",
    "**silhouette**. It can also be defined as how identical/similar a data point 'x' is to the data points inside the cluster to \n",
    "\n",
    "which x is assigned. Its value ranges from -1 to 1 where 1 means good and -1 means bad.\n",
    "\n",
    "\n",
    "\n",
    "Curve plotted between True Positive Rate and False Positive Rate is Receiver Operating Characteristics curve and is used to \n",
    "\n",
    "find the area under the curve for **ROC-AUC score** for binary classification evaluation. True Positive Rate and False Positive \n",
    "\n",
    "Rate are calculated for different thresholds values where thresholds take values starting from the highest probability scores \n",
    "\n",
    "assigned to data points and goes up to the lowest probability score. The curve is impacted by presence of outliers, and simple \n",
    "\n",
    "models. Extensions can be made to this curve to suit multiclass classification evaluation requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a67799",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
